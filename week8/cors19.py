# -*- coding: utf-8 -*-
"""cors19.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kgol5c1amxIwkFgn0zURMxqlSQKqnOJL
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from collections import Counter

sns.set(style="whitegrid")


# ==== Part 1: Download and Load Data ====
file_path = "/content/metadata_sample.csv"
df = pd.read_csv(file_path, low_memory=False)
print("✅ Data loaded successfully!")
print(df.head())

print("\n--- Basic Exploration ---")
print("Shape:", df.shape)
print("\nData types:\n", df.dtypes.head(20))
print("\nMissing values:\n", df[['title', 'abstract', 'publish_time', 'journal']].isnull().sum())
print("\nStatistics:\n", df.describe())

# ==== Part 2: Data Cleaning & Preparation ====
print("\n--- Data Cleaning ---")
missing_summary = df.isnull().mean().sort_values(ascending=False)
print("Columns with highest missing %:\n", missing_summary.head(20))

df_clean = df.copy()
df_clean = df_clean.dropna(subset=['title', 'abstract', 'publish_time'])

df_clean['publish_time'] = pd.to_datetime(df_clean['publish_time'], errors='coerce')
df_clean = df_clean.dropna(subset=['publish_time'])

df_clean['year'] = df_clean['publish_time'].dt.year
df_clean['abstract_word_count'] = df_clean['abstract'].apply(lambda x: len(str(x).split()))

print("Cleaned shape:", df_clean.shape)
print(df_clean.head())

print("\n--- Analysis & Visualization ---")

# Papers by year
year_counts = df_clean['year'].value_counts().sort_index()
plt.figure(figsize=(10, 6))
year_counts.plot(kind='bar', title="Number of Papers by Year")
plt.show()

# Top journals
top_journals = df_clean['journal'].value_counts().head(10)
plt.figure(figsize=(10, 6))
top_journals.plot(kind='barh', title="Top Journals")
plt.show()

# Word frequency from titles
words = " ".join(df_clean['title'].dropna().astype(str)).lower().split()
word_freq = Counter(words)
print("Top 20 title words:\n", word_freq.most_common(20))

# Word cloud
text = " ".join(df_clean['title'].dropna().astype(str))
wordcloud = WordCloud(width=800, height=400, background_color="white").generate(text)
plt.figure(figsize=(12, 6))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.title("Word Cloud of Paper Titles")
plt.show()

# Distribution by source
if 'source_x' in df_clean.columns:
    plt.figure(figsize=(10, 6))
    df_clean['source_x'].value_counts().head(10).plot(kind='bar', title="Top Sources")
    plt.show()
else:
    print("⚠️ No 'source_x' column found in this dataset.")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import matplotlib.pyplot as plt
# from wordcloud import WordCloud
# 
# st.title("CORD-19 Data Explorer")
# st.write("Interactive exploration of COVID-19 research papers")
# 
# df = pd.read_csv("metadata_sample.csv", low_memory=False)
# df['publish_time'] = pd.to_datetime(df['publish_time'], errors='coerce')
# df['year'] = df['publish_time'].dt.year
# 
# year_range = st.slider("Select year range", 2019, 2022, (2020, 2021))
# mask = df['year'].between(year_range[0], year_range[1])
# subset = df[mask]
# 
# st.subheader("Publications Over Time")
# year_counts = subset['year'].value_counts().sort_index()
# st.bar_chart(year_counts)
#